[TOC]



# 0. 知识准备

询问chatgpt相关背景知识：

![image-20240521092526511](C:\Users\gorsonpy\AppData\Roaming\Typora\typora-user-images\image-20240521092526511.png)



# 1.导入包集

```python
data = pd.read_csv('/home/dataset/BlackFriday.csv')
data
```

显示数据集:

![image-20240521091421280](C:\Users\gorsonpy\AppData\Roaming\Typora\typora-user-images\image-20240521091421280.png)

# 3. 数据预处理

## 3.1 检查并处理缺失值

```python
blank = data.isnull().sum()
blank
```

![image-20240521092142899](C:\Users\gorsonpy\AppData\Roaming\Typora\typora-user-images\image-20240521092142899.png)

```python
data = data.drop(['Product_Category_2', 'Product_Category_3'], axis = 1)
```

```python
blank = data.isnull().sum()
blank
```

![image-20240521092257304](C:\Users\gorsonpy\AppData\Roaming\Typora\typora-user-images\image-20240521092257304.png)

## 3.2 删除无用的列

```python
data = data.drop(['User_ID', 'Product_ID'], axis = 1)
```

## 3.3 检查类别变量

```python
print(data.dtypes)
```

![image-20240521092441167](C:\Users\gorsonpy\AppData\Roaming\Typora\typora-user-images\image-20240521092441167.png)

```python
# 转换变量类型
data['Stay_In_Current_City_Years'] = data['Stay_In_Current_City_Years'].astype('int64')
data['Product_Category_1'] = data['Product_Category_1'].astype('object')
data['Occupation'] = data['Occupation'].astype('object')
data['Marital_Status'] = data['Marital_Status'].astype('object')

# 替换4+
data['Stay_In_Current_City_Years'].replace('4+', 4, inplace = True)
```

```python
print(data.dtypes)
```

![image-20240521092857736](C:\Users\gorsonpy\AppData\Roaming\Typora\typora-user-images\image-20240521092857736.png)

## 3.4 标签编码

```python
data = pd.get_dummies(data, drop_first = True)
data
```

![image-20240521093105520](C:\Users\gorsonpy\AppData\Roaming\Typora\typora-user-images\image-20240521093105520.png)

## 3.5 得到自变量和因变量

```python
# 得到自变量和因变量
y = data['Purchase'].values
data = data.drop(['Purchase'], axis = 1)
x = data.values
```

## 3.6 拆分训练集和测试集

```python
# 拆分训练集和测试集
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 1)
print(x_train.shape)
print(x_test.shape)
print(y_train.shape)
print(y_test.shape)
```

![image-20240521093248552](C:\Users\gorsonpy\AppData\Roaming\Typora\typora-user-images\image-20240521093248552.png)

## 3.7 特征缩放

```python
# 特征缩放
from sklearn.preprocessing import StandardScaler
sc_x = StandardScaler()
x_train = sc_x.fit_transform(x_train)
x_test = sc_x.transform(x_test)
sc_y = StandardScaler()
y_train = np.ravel(sc_y.fit_transform(y_train.reshape(-1, 1)))
```

# 4. 用不同参数构建AdaBoost回归模型

## 4.1 模型一

### 4.1.1 构建模型

```python
# 使用不同的参数构建AdaBoost回归模型
# 模型1
from sklearn.ensemble import AdaBoostRegressor
regressor = AdaBoostRegressor(n_estimators=50, learning_rate=1, loss='linear', random_state=0)
regressor.fit(x_train, y_train)
```

![image-20240521093513810](C:\Users\gorsonpy\AppData\Roaming\Typora\typora-user-images\image-20240521093513810.png)

### 4.1.2 测试

```python
# 在测试集做预测
y_pred = regressor.predict(x_test)
y_pred[:5]
```

![image-20240521093936573](C:\Users\gorsonpy\AppData\Roaming\Typora\typora-user-images\image-20240521093936573.png)

```python
# y_pred变回特征缩放之前的
y_pred = sc_y.inverse_transform(y_pred)
y_pred[:5]
```

![image-20240521094734274](C:\Users\gorsonpy\AppData\Roaming\Typora\typora-user-images\image-20240521094734274.png)

### 4.1.3 评估模型性能

```python
# 评估模型性能
from sklearn.metrics import r2_score
r2 = r2_score(y_test, y_pred)
print("R2 Score:", r2)
```

![image-20240521094803550](C:\Users\gorsonpy\AppData\Roaming\Typora\typora-user-images\image-20240521094803550.png)

## 4.2 模型二

### 4.2.1 建立模型

```python
# 模型2
from sklearn.tree import DecisionTreeRegressor
regressor = AdaBoostRegressor(base_estimator = DecisionTreeRegressor(min_samples_split=100, max_depth=10, min_samples_leaf=10), 
                              n_estimators=1000, learning_rate=0.2, loss='linear', random_state=0)
regressor.fit(x_train, y_train)
```

![image-20240521094938997](C:\Users\gorsonpy\AppData\Roaming\Typora\typora-user-images\image-20240521094938997.png)

### 4.2.2 预测

```python
# 在测试集做预测
y_pred = regressor.predict(x_test)
y_pred[:5]
```

![image-20240521095159422](C:\Users\gorsonpy\AppData\Roaming\Typora\typora-user-images\image-20240521095159422.png)

```python
y_pred = sc_y.inverse_transform(y_pred) # y_pred变回特征缩放之前的
y_pred[:5]
```

![image-20240521095219503](C:\Users\gorsonpy\AppData\Roaming\Typora\typora-user-images\image-20240521095219503.png)

### 4.2.3 评估模型性能

```python
# 评估模型性能
r2 = r2_score(y_test, y_pred)
print("R2 Score:", r2)
```

![image-20240521095247241](C:\Users\gorsonpy\AppData\Roaming\Typora\typora-user-images\image-20240521095247241.png)

# 5 实验结论

1. **使用AdaBoost可以解决回归问题**
   在本实验中，采用AdaBoost算法进行了回归分析。实验结果表明，AdaBoost不仅适用于分类问题，在处理回归问题上同样表现出色。通过集成多个弱回归模型，AdaBoost能够有效地提高预测的准确性和稳健性。实验结果显示，AdaBoost在处理复杂的非线性关系时表现出较强的适应能力，能够提供较高的预测精度。因此，可以确认AdaBoost是一种有效的回归方法，能够应用于各种回归任务中。
2. **不同超参数对模型性能的影响不同**
   实验进一步探讨了不同超参数设置对AdaBoost模型性能的影响。通过调整学习率、弱学习器数量等关键超参数，观察到模型的预测性能有显著变化。例如，适当增加弱学习器的数量可以提高模型的预测能力，但过多的学习器可能导致过拟合。同样，学习率的选择对模型收敛速度和预测精度也有显著影响。较高的学习率可能导致模型过拟合，而较低的学习率可能导致模型欠拟合。实验结果表明，优化超参数是提升AdaBoost回归模型性能的关键步骤，不同数据集和问题类型需要针对性地调整超参数设置，以获得最佳的模型性能。

通过上述实验，我们不仅验证了AdaBoost在回归问题上的有效性，还强调了超参数调优在模型训练中的重要性，为后续的模型应用和优化提供了宝贵的参考。